# 文档管理服务详细实现指南

## 一、架构设计

### 1.1 整体架构

```
┌─────────────────────────────────────────────────────────────┐
│                    文档管理服务架构                           │
└─────────────────────────────────────────────────────────────┘

【Controller 层】
DocumentController
    ├── uploadDocument()      - 文档上传接口
    ├── listDocuments()       - 文档列表接口
    ├── getDocument()         - 文档详情接口
    └── deleteDocument()      - 删除文档接口

【Service 层】
DocumentService (接口)
    ├── uploadDocument()      - 上传文档（含解析）
    ├── parseDocument()       - 解析文档（提取文本）
    ├── listDocuments()       - 获取文档列表
    ├── getDocument()         - 获取文档详情
    └── deleteDocument()      - 删除文档

DocumentServiceImpl (实现)
    ├── 文档上传逻辑
    ├── 文档解析逻辑
    ├── 文档存储逻辑
    └── 文档查询逻辑

ChunkService (接口)
    ├── chunkDocument()       - 切分文档
    └── chunkText()           - 切分文本

ChunkServiceImpl (实现)
    ├── 固定大小切分
    ├── 重叠机制
    └── 边界处理

【Mapper 层】
DocumentMapper
    └── 继承 BaseMapper<Document>

ChunkMapper
    └── 继承 BaseMapper<Chunk>

【Entity 层】
Document (实体)
    ├── id, tenantId, title, content
    ├── source, fileType, fileSize
    └── status, createTime, updateTime

Chunk (实体)
    ├── id, documentId, tenantId
    ├── chunkIndex, content
    └── createTime
```

### 1.2 数据流向

```
用户上传文档
    ↓
DocumentController.uploadDocument()
    ↓
DocumentService.uploadDocument()
    ├── 1. 解析文档（parseDocument）
    ├── 2. 保存到数据库（Document）
    ├── 3. 切分文档（ChunkService.chunkDocument）
    └── 4. 保存 Chunk 到数据库
    ↓
返回文档ID
```

### 1.3 模块划分

**包结构**：
```
com.ityfz.yulu.knowledge
├── controller
│   └── DocumentController.java
├── service
│   ├── DocumentService.java
│   ├── ChunkService.java
│   ├── impl
│   │   ├── DocumentServiceImpl.java
│   │   └── ChunkServiceImpl.java
├── entity
│   ├── Document.java
│   └── Chunk.java
├── mapper
│   ├── DocumentMapper.java
│   └── ChunkMapper.java
└── dto
    ├── DocumentUploadRequest.java
    ├── DocumentListResponse.java
    └── DocumentDetailResponse.java
```

---

## 二、数据库设计

### 2.1 知识库文档表（knowledge_document）

```sql
CREATE TABLE `knowledge_document` (
  `id` BIGINT PRIMARY KEY AUTO_INCREMENT COMMENT '文档ID',
  `tenant_id` BIGINT NOT NULL COMMENT '租户ID',
  `title` VARCHAR(255) NOT NULL COMMENT '文档标题',
  `content` TEXT NOT NULL COMMENT '文档内容（纯文本）',
  `source` VARCHAR(255) DEFAULT NULL COMMENT '来源（用户上传/FAQ/产品手册/帮助文档等）',
  `file_type` VARCHAR(50) DEFAULT NULL COMMENT '文件类型（txt/pdf/docx/md等）',
  `file_size` BIGINT DEFAULT NULL COMMENT '文件大小（字节）',
  `status` TINYINT DEFAULT 0 COMMENT '状态：0-未索引 1-已索引 2-索引失败',
  `indexed_at` DATETIME DEFAULT NULL COMMENT '索引时间',
  `create_time` DATETIME DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',
  `update_time` DATETIME DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '更新时间',
  INDEX `idx_tenant_status` (`tenant_id`, `status`),
  INDEX `idx_tenant_create` (`tenant_id`, `create_time`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='知识库文档表';
```

**字段说明**：
- `id`: 主键，自增
- `tenant_id`: 租户ID，用于多租户隔离
- `title`: 文档标题，用户输入或从文件名提取
- `content`: 文档内容（纯文本），解析后的文本
- `source`: 文档来源，用于分类和过滤
- `file_type`: 原始文件类型
- `file_size`: 文件大小（字节）
- `status`: 状态（0-未索引，1-已索引，2-索引失败）
- `indexed_at`: 索引时间（后续 RAG 索引时更新）

### 2.2 文档切分表（knowledge_chunk）

```sql
CREATE TABLE `knowledge_chunk` (
  `id` BIGINT PRIMARY KEY AUTO_INCREMENT COMMENT 'Chunk ID',
  `document_id` BIGINT NOT NULL COMMENT '文档ID',
  `tenant_id` BIGINT NOT NULL COMMENT '租户ID',
  `chunk_index` INT NOT NULL COMMENT '在文档中的序号（从0开始）',
  `content` TEXT NOT NULL COMMENT 'Chunk 内容',
  `content_length` INT DEFAULT NULL COMMENT '内容长度（字符数）',
  `qdrant_point_id` BIGINT DEFAULT NULL COMMENT 'Qdrant 中的 Point ID（后续索引时填充）',
  `create_time` DATETIME DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',
  INDEX `idx_document` (`document_id`),
  INDEX `idx_tenant` (`tenant_id`),
  INDEX `idx_qdrant_point` (`qdrant_point_id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='文档切分表';
```

**字段说明**：
- `id`: 主键，自增
- `document_id`: 关联的文档ID
- `tenant_id`: 租户ID（冗余字段，便于查询）
- `chunk_index`: Chunk 在文档中的序号（0, 1, 2, ...）
- `content`: Chunk 的文本内容
- `content_length`: 内容长度（字符数），便于统计和过滤
- `qdrant_point_id`: Qdrant 中的 Point ID（后续向量索引时填充）

---

## 三、实体类设计

### 3.1 Document 实体类

**文件路径**：`src/main/java/com/ityfz/yulu/knowledge/entity/Document.java`

```java
package com.ityfz.yulu.knowledge.entity;

import com.baomidou.mybatisplus.annotation.*;
import lombok.Data;

import java.time.LocalDateTime;

/**
 * 知识库文档实体
 */
@Data
@TableName("knowledge_document")
public class Document {
    
    /**
     * 文档ID（主键）
     */
    @TableId(type = IdType.AUTO)
    private Long id;
    
    /**
     * 租户ID
     */
    private Long tenantId;
    
    /**
     * 文档标题
     */
    private String title;
    
    /**
     * 文档内容（纯文本）
     */
    private String content;
    
    /**
     * 来源（用户上传/FAQ/产品手册/帮助文档等）
     */
    private String source;
    
    /**
     * 文件类型（txt/pdf/docx/md等）
     */
    private String fileType;
    
    /**
     * 文件大小（字节）
     */
    private Long fileSize;
    
    /**
     * 状态：0-未索引 1-已索引 2-索引失败
     */
    private Integer status;
    
    /**
     * 索引时间
     */
    private LocalDateTime indexedAt;
    
    /**
     * 创建时间（自动填充）
     */
    @TableField(fill = FieldFill.INSERT)
    private LocalDateTime createTime;
    
    /**
     * 更新时间（自动填充）
     */
    @TableField(fill = FieldFill.INSERT_UPDATE)
    private LocalDateTime updateTime;
}
```

**设计要点**：
- 使用 `@TableName` 指定表名
- 使用 `@TableId(type = IdType.AUTO)` 指定主键自增
- 使用 `@TableField(fill = FieldFill.INSERT)` 自动填充创建时间
- 使用 `@TableField(fill = FieldFill.INSERT_UPDATE)` 自动填充更新时间

### 3.2 Chunk 实体类

**文件路径**：`src/main/java/com/ityfz/yulu/knowledge/entity/Chunk.java`

```java
package com.ityfz.yulu.knowledge.entity;

import com.baomidou.mybatisplus.annotation.*;
import lombok.Data;

import java.time.LocalDateTime;

/**
 * 文档切分实体
 */
@Data
@TableName("knowledge_chunk")
public class Chunk {
    
    /**
     * Chunk ID（主键）
     */
    @TableId(type = IdType.AUTO)
    private Long id;
    
    /**
     * 文档ID
     */
    private Long documentId;
    
    /**
     * 租户ID（冗余字段，便于查询）
     */
    private Long tenantId;
    
    /**
     * 在文档中的序号（从0开始）
     */
    private Integer chunkIndex;
    
    /**
     * Chunk 内容
     */
    private String content;
    
    /**
     * 内容长度（字符数）
     */
    private Integer contentLength;
    
    /**
     * Qdrant 中的 Point ID（后续向量索引时填充）
     */
    private Long qdrantPointId;
    
    /**
     * 创建时间（自动填充）
     */
    @TableField(fill = FieldFill.INSERT)
    private LocalDateTime createTime;
}
```

---

## 四、Mapper 接口设计

### 4.1 DocumentMapper

**文件路径**：`src/main/java/com/ityfz/yulu/knowledge/mapper/DocumentMapper.java`

```java
package com.ityfz.yulu.knowledge.mapper;

import com.baomidou.mybatisplus.core.mapper.BaseMapper;
import com.ityfz.yulu.knowledge.entity.Document;
import org.apache.ibatis.annotations.Mapper;

/**
 * 文档 Mapper
 */
@Mapper
public interface DocumentMapper extends BaseMapper<Document> {
    // MyBatis Plus 已经提供了基础的 CRUD 方法
    // 如果需要自定义查询，可以在这里添加方法
}
```

### 4.2 ChunkMapper

**文件路径**：`src/main/java/com/ityfz/yulu/knowledge/mapper/ChunkMapper.java`

```java
package com.ityfz.yulu.knowledge.mapper;

import com.baomidou.mybatisplus.core.mapper.BaseMapper;
import com.ityfz.yulu.knowledge.entity.Chunk;
import org.apache.ibatis.annotations.Mapper;
import org.apache.ibatis.annotations.Param;

import java.util.List;

/**
 * 文档切分 Mapper
 */
@Mapper
public interface ChunkMapper extends BaseMapper<Chunk> {
    
    /**
     * 根据文档ID查询所有 Chunk（按序号排序）
     */
    List<Chunk> selectByDocumentId(@Param("documentId") Long documentId);
    
    /**
     * 根据文档ID删除所有 Chunk
     */
    void deleteByDocumentId(@Param("documentId") Long documentId);
}
```

**注意**：如果使用 MyBatis Plus，`selectByDocumentId` 和 `deleteByDocumentId` 可以通过 Lambda 查询实现，不一定需要自定义 SQL。但这里给出示例，方便理解。

---

## 五、Service 接口设计

### 5.1 DocumentService 接口（完善现有接口）

**文件路径**：`src/main/java/com/ityfz/yulu/knowledge/service/DocumentService.java`

```java
package com.ityfz.yulu.knowledge.service;

import com.ityfz.yulu.knowledge.entity.Document;
import org.springframework.web.multipart.MultipartFile;

import java.util.List;

/**
 * 文档管理服务接口
 */
public interface DocumentService {
    
    /**
     * 上传文档（支持文件上传和文本内容）
     * 
     * @param tenantId 租户ID
     * @param title 文档标题
     * @param file 上传的文件（可选）
     * @param content 文本内容（如果 file 为空，则使用 content）
     * @param source 文档来源（用户上传/FAQ/产品手册等）
     * @return 文档ID
     */
    Long uploadDocument(Long tenantId, String title, MultipartFile file, String content, String source);
    
    /**
     * 解析文档（提取纯文本）
     * 
     * @param fileBytes 文件字节数组
     * @param fileType 文件类型（txt/pdf/docx/md等）
     * @return 解析后的纯文本
     */
    String parseDocument(byte[] fileBytes, String fileType);
    
    /**
     * 获取文档列表（分页）
     * 
     * @param tenantId 租户ID
     * @param pageNum 页码（从1开始）
     * @param pageSize 每页大小
     * @return 文档列表
     */
    List<Document> listDocuments(Long tenantId, Integer pageNum, Integer pageSize);
    
    /**
     * 获取文档详情
     * 
     * @param documentId 文档ID
     * @param tenantId 租户ID（用于权限校验）
     * @return 文档详情
     */
    Document getDocument(Long documentId, Long tenantId);
    
    /**
     * 删除文档（同时删除关联的 Chunk）
     * 
     * @param documentId 文档ID
     * @param tenantId 租户ID（用于权限校验）
     */
    void deleteDocument(Long documentId, Long tenantId);
    
    /**
     * 更新文档状态
     * 
     * @param documentId 文档ID
     * @param status 状态（0-未索引 1-已索引 2-索引失败）
     */
    void updateDocumentStatus(Long documentId, Integer status);
}
```

### 5.2 ChunkService 接口

**文件路径**：`src/main/java/com/ityfz/yulu/knowledge/service/ChunkService.java`

```java
package com.ityfz.yulu.knowledge.service;

import com.ityfz.yulu.knowledge.entity.Chunk;

import java.util.List;

/**
 * 文档切分服务接口
 */
public interface ChunkService {
    
    /**
     * 切分文档内容
     * 
     * @param content 文档内容
     * @param chunkSize 每个 Chunk 的最大字符数
     * @param overlapSize 重叠字符数
     * @return Chunk 列表（按顺序）
     */
    List<Chunk> chunkText(String content, int chunkSize, int overlapSize);
    
    /**
     * 切分文档并保存到数据库
     * 
     * @param documentId 文档ID
     * @param tenantId 租户ID
     * @param content 文档内容
     * @param chunkSize 每个 Chunk 的最大字符数
     * @param overlapSize 重叠字符数
     * @return 保存的 Chunk 列表
     */
    List<Chunk> chunkAndSave(Long documentId, Long tenantId, String content, 
                              int chunkSize, int overlapSize);
    
    /**
     * 根据文档ID获取所有 Chunk
     * 
     * @param documentId 文档ID
     * @return Chunk 列表（按序号排序）
     */
    List<Chunk> getChunksByDocumentId(Long documentId);
    
    /**
     * 根据文档ID删除所有 Chunk
     * 
     * @param documentId 文档ID
     */
    void deleteChunksByDocumentId(Long documentId);
}
```

---

## 六、实现步骤（分步详细说明）

### 步骤1：创建数据库表

**操作**：
1. 打开 MySQL 客户端（Navicat、DBeaver 或命令行）
2. 连接到你的数据库（`yulu`）
3. 执行上面的 SQL 语句创建两个表

**验证**：
```sql
-- 查看表是否创建成功
SHOW TABLES LIKE 'knowledge%';

-- 查看表结构
DESC knowledge_document;
DESC knowledge_chunk;
```

### 步骤2：创建实体类

**操作**：
1. 创建包：`src/main/java/com/ityfz/yulu/knowledge/entity/`
2. 创建 `Document.java`（复制上面的代码）
3. 创建 `Chunk.java`（复制上面的代码）

**注意事项**：
- 确保包名正确
- 确保导入的注解正确（`@TableName`, `@TableId`, `@TableField` 等）
- 确保 Lombok 的 `@Data` 注解可用

**验证**：
- 编译项目，确保没有语法错误
- 检查 IDE 是否识别了实体类

### 步骤3：创建 Mapper 接口

**操作**：
1. 创建包：`src/main/java/com/ityfz/yulu/knowledge/mapper/`
2. 创建 `DocumentMapper.java`（复制上面的代码）
3. 创建 `ChunkMapper.java`（复制上面的代码）

**注意事项**：
- 确保添加 `@Mapper` 注解
- 确保继承 `BaseMapper<Entity>`
- 如果使用 MyBatis Plus，`ChunkMapper` 中的自定义方法可以通过 Lambda 查询实现

**验证**：
- 编译项目，确保没有错误
- 检查 Spring 是否能扫描到 Mapper

### 步骤4：实现 ChunkService（先实现切分逻辑）

**文件路径**：`src/main/java/com/ityfz/yulu/knowledge/service/impl/ChunkServiceImpl.java`

**实现思路**：

1. **固定大小切分**：
   - 将文本按固定大小（如 500 字符）切分
   - 如果最后一个 Chunk 小于最小大小，合并到前一个 Chunk

2. **重叠机制**：
   - 每个 Chunk 与前一个 Chunk 有重叠（如 50 字符）
   - 重叠部分保证上下文连贯性

3. **边界处理**：
   - 避免在句子中间切分（尽量在句号、换行处切分）
   - 处理特殊字符（换行符、制表符等）

**完整代码示例**：

```java
package com.ityfz.yulu.knowledge.service.impl;

import com.ityfz.yulu.knowledge.entity.Chunk;
import com.ityfz.yulu.knowledge.mapper.ChunkMapper;
import com.ityfz.yulu.knowledge.service.ChunkService;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.stereotype.Service;
import org.springframework.transaction.annotation.Transactional;

import java.util.ArrayList;
import java.util.List;

/**
 * 文档切分服务实现
 */
@Slf4j
@Service
public class ChunkServiceImpl implements ChunkService {
    
    @Autowired
    private ChunkMapper chunkMapper;
    
    // 从配置文件读取默认值
    @Value("${rag.chunk.size:500}")
    private int defaultChunkSize;
    
    @Value("${rag.chunk.overlap:50}")
    private int defaultOverlapSize;
    
    @Value("${rag.chunk.min-size:50}")
    private int minChunkSize;
    
    @Override
    public List<Chunk> chunkText(String content, int chunkSize, int overlapSize) {
        if (content == null || content.trim().isEmpty()) {
            return new ArrayList<>();
        }
        
        // 预处理：统一换行符，清理多余空白
        String normalizedContent = normalizeContent(content);
        
        List<Chunk> chunks = new ArrayList<>();
        int contentLength = normalizedContent.length();
        
        // 如果内容长度小于 chunkSize，直接返回一个 Chunk
        if (contentLength <= chunkSize) {
            Chunk chunk = new Chunk();
            chunk.setContent(normalizedContent);
            chunk.setContentLength(normalizedContent.length());
            chunk.setChunkIndex(0);
            chunks.add(chunk);
            return chunks;
        }
        
        // 切分逻辑
        int start = 0;
        int chunkIndex = 0;
        
        while (start < contentLength) {
            // 计算当前 Chunk 的结束位置
            int end = Math.min(start + chunkSize, contentLength);
            
            // 如果不是最后一个 Chunk，尝试在句子边界切分
            if (end < contentLength) {
                end = findBestSplitPoint(normalizedContent, start, end);
            }
            
            // 提取 Chunk 内容
            String chunkContent = normalizedContent.substring(start, end).trim();
            
            // 如果 Chunk 内容不为空，创建 Chunk
            if (!chunkContent.isEmpty()) {
                Chunk chunk = new Chunk();
                chunk.setContent(chunkContent);
                chunk.setContentLength(chunkContent.length());
                chunk.setChunkIndex(chunkIndex);
                chunks.add(chunk);
                chunkIndex++;
            }
            
            // 计算下一个 Chunk 的起始位置（考虑重叠）
            start = end - overlapSize;
            if (start < 0) {
                start = 0;
            }
            
            // 如果已经到达末尾，退出循环
            if (end >= contentLength) {
                break;
            }
        }
        
        // 处理最后一个 Chunk：如果太小，合并到前一个
        if (chunks.size() > 1) {
            Chunk lastChunk = chunks.get(chunks.size() - 1);
            if (lastChunk.getContentLength() < minChunkSize) {
                Chunk prevChunk = chunks.get(chunks.size() - 2);
                prevChunk.setContent(prevChunk.getContent() + "\n" + lastChunk.getContent());
                prevChunk.setContentLength(prevChunk.getContent().length());
                chunks.remove(chunks.size() - 1);
            }
        }
        
        log.debug("[ChunkService] 切分完成: 原文长度={}, Chunk数量={}", contentLength, chunks.size());
        return chunks;
    }
    
    @Override
    @Transactional
    public List<Chunk> chunkAndSave(Long documentId, Long tenantId, String content, 
                                     int chunkSize, int overlapSize) {
        // 1. 切分文档
        List<Chunk> chunks = chunkText(content, chunkSize, overlapSize);
        
        // 2. 设置文档ID和租户ID，保存到数据库
        for (Chunk chunk : chunks) {
            chunk.setDocumentId(documentId);
            chunk.setTenantId(tenantId);
            chunkMapper.insert(chunk);
        }
        
        log.info("[ChunkService] 文档切分并保存: documentId={}, chunkCount={}", documentId, chunks.size());
        return chunks;
    }
    
    @Override
    public List<Chunk> getChunksByDocumentId(Long documentId) {
        return chunkMapper.selectList(
            com.baomidou.mybatisplus.core.toolkit.Wrappers.<Chunk>lambdaQuery()
                .eq(Chunk::getDocumentId, documentId)
                .orderByAsc(Chunk::getChunkIndex)
        );
    }
    
    @Override
    @Transactional
    public void deleteChunksByDocumentId(Long documentId) {
        chunkMapper.delete(
            com.baomidou.mybatisplus.core.toolkit.Wrappers.<Chunk>lambdaQuery()
                .eq(Chunk::getDocumentId, documentId)
        );
        log.info("[ChunkService] 删除文档的所有 Chunk: documentId={}", documentId);
    }
    
    /**
     * 规范化内容：统一换行符，清理多余空白
     */
    private String normalizeContent(String content) {
        if (content == null) {
            return "";
        }
        // 统一换行符为 \n
        String normalized = content.replaceAll("\r\n", "\n").replaceAll("\r", "\n");
        // 清理连续的空行（保留单个换行）
        normalized = normalized.replaceAll("\n{3,}", "\n\n");
        return normalized.trim();
    }
    
    /**
     * 寻找最佳切分点（尽量在句子边界）
     */
    private int findBestSplitPoint(String content, int start, int end) {
        // 在 end 位置向前查找，寻找句子边界（句号、问号、感叹号、换行符）
        int searchStart = Math.max(start, end - 100); // 最多向前查找 100 个字符
        
        for (int i = end - 1; i >= searchStart; i--) {
            char c = content.charAt(i);
            // 如果遇到句子结束符，在此处切分
            if (c == '。' || c == '！' || c == '？' || c == '.' || c == '!' || c == '?') {
                return i + 1;
            }
            // 如果遇到换行符，也可以在此处切分
            if (c == '\n') {
                return i + 1;
            }
        }
        
        // 如果没找到合适的切分点，返回原始 end
        return end;
    }
}
```

**实现要点**：
1. **规范化内容**：统一换行符，清理多余空白
2. **智能切分**：尽量在句子边界切分，避免截断句子
3. **重叠机制**：每个 Chunk 与前一个有重叠，保证上下文连贯
4. **边界处理**：处理最后一个过小的 Chunk（合并到前一个）

### 步骤5：实现 DocumentService（文档管理核心逻辑）

**文件路径**：`src/main/java/com/ityfz/yulu/knowledge/service/impl/DocumentServiceImpl.java`

**实现思路**：

1. **文档上传**：
   - 接收文件或文本内容
   - 解析文档（提取纯文本）
   - 保存到数据库
   - 切分文档并保存 Chunk

2. **文档解析**：
   - 支持 TXT：直接读取文本
   - 支持 MD：直接读取文本（Markdown）
   - 支持 PDF：使用 Apache PDFBox 或 Tika（后续扩展）
   - 支持 DOCX：使用 Apache POI（后续扩展）

3. **文档查询**：
   - 分页查询
   - 按租户过滤
   - 按状态过滤

4. **文档删除**：
   - 删除文档记录
   - 删除关联的 Chunk 记录
   - 后续还需要删除 Qdrant 中的向量（索引服务实现）

**完整代码示例**：

```java
package com.ityfz.yulu.knowledge.service.impl;

import com.baomidou.mybatisplus.core.conditions.query.LambdaQueryWrapper;
import com.baomidou.mybatisplus.extension.plugins.pagination.Page;
import com.ityfz.yulu.common.enums.ErrorCodes;
import com.ityfz.yulu.common.exception.BizException;
import com.ityfz.yulu.knowledge.entity.Document;
import com.ityfz.yulu.knowledge.entity.Chunk;
import com.ityfz.yulu.knowledge.mapper.DocumentMapper;
import com.ityfz.yulu.knowledge.service.ChunkService;
import com.ityfz.yulu.knowledge.service.DocumentService;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.stereotype.Service;
import org.springframework.transaction.annotation.Transactional;
import org.springframework.web.multipart.MultipartFile;

import java.io.IOException;
import java.nio.charset.StandardCharsets;
import java.time.LocalDateTime;
import java.util.List;

/**
 * 文档管理服务实现
 */
@Slf4j
@Service
public class DocumentServiceImpl implements DocumentService {
    
    @Autowired
    private DocumentMapper documentMapper;
    
    @Autowired
    private ChunkService chunkService;
    
    // 从配置文件读取
    @Value("${rag.chunk.size:500}")
    private int chunkSize;
    
    @Value("${rag.chunk.overlap:50}")
    private int overlapSize;
    
    @Value("${rag.document.max-size:10485760}")  // 默认 10MB
    private long maxFileSize;
    
    @Override
    @Transactional
    public Long uploadDocument(Long tenantId, String title, MultipartFile file, 
                                String content, String source) {
        // 1. 参数校验
        if (tenantId == null) {
            throw new BizException(ErrorCodes.VALIDATION_ERROR, "租户ID不能为空");
        }
        if (title == null || title.trim().isEmpty()) {
            throw new BizException(ErrorCodes.VALIDATION_ERROR, "文档标题不能为空");
        }
        
        String parsedContent;
        String fileType = null;
        Long fileSize = null;
        
        // 2. 解析文档内容
        if (file != null && !file.isEmpty()) {
            // 从文件解析
            try {
                // 检查文件大小
                if (file.getSize() > maxFileSize) {
                    throw new BizException(ErrorCodes.VALIDATION_ERROR, 
                        "文件大小超过限制: " + (maxFileSize / 1024 / 1024) + "MB");
                }
                
                fileType = getFileType(file.getOriginalFilename());
                fileSize = file.getSize();
                parsedContent = parseDocument(file.getBytes(), fileType);
                
                // 如果标题为空，使用文件名
                if (title == null || title.trim().isEmpty()) {
                    title = file.getOriginalFilename();
                }
            } catch (IOException e) {
                log.error("[DocumentService] 文件读取失败", e);
                throw new BizException(ErrorCodes.SYSTEM_ERROR, "文件读取失败: " + e.getMessage());
            }
        } else if (content != null && !content.trim().isEmpty()) {
            // 直接使用文本内容
            parsedContent = content.trim();
            fileType = "text";
            fileSize = (long) parsedContent.getBytes(StandardCharsets.UTF_8).length;
        } else {
            throw new BizException(ErrorCodes.VALIDATION_ERROR, "文件或内容不能同时为空");
        }
        
        // 3. 保存文档到数据库
        Document document = new Document();
        document.setTenantId(tenantId);
        document.setTitle(title);
        document.setContent(parsedContent);
        document.setSource(source != null ? source : "用户上传");
        document.setFileType(fileType);
        document.setFileSize(fileSize);
        document.setStatus(0);  // 0-未索引
        document.setCreateTime(LocalDateTime.now());
        document.setUpdateTime(LocalDateTime.now());
        
        documentMapper.insert(document);
        Long documentId = document.getId();
        
        log.info("[DocumentService] 文档上传成功: documentId={}, tenantId={}, title={}, contentLength={}", 
            documentId, tenantId, title, parsedContent.length());
        
        // 4. 切分文档并保存 Chunk
        try {
            chunkService.chunkAndSave(documentId, tenantId, parsedContent, chunkSize, overlapSize);
            log.info("[DocumentService] 文档切分完成: documentId={}", documentId);
        } catch (Exception e) {
            log.error("[DocumentService] 文档切分失败: documentId={}", documentId, e);
            // 切分失败不影响文档保存，但记录错误
            document.setStatus(2);  // 2-索引失败
            documentMapper.updateById(document);
        }
        
        return documentId;
    }
    
    @Override
    public String parseDocument(byte[] fileBytes, String fileType) {
        if (fileBytes == null || fileBytes.length == 0) {
            throw new BizException(ErrorCodes.VALIDATION_ERROR, "文件内容为空");
        }
        
        if (fileType == null) {
            fileType = "txt";  // 默认按文本处理
        }
        
        String lowerFileType = fileType.toLowerCase();
        
        try {
            switch (lowerFileType) {
                case "txt":
                case "text":
                    return parseTxt(fileBytes);
                    
                case "md":
                case "markdown":
                    return parseMarkdown(fileBytes);
                    
                case "pdf":
                    // TODO: 后续实现 PDF 解析
                    throw new BizException(ErrorCodes.VALIDATION_ERROR, "PDF 解析功能暂未实现");
                    
                case "docx":
                case "doc":
                    // TODO: 后续实现 DOCX 解析
                    throw new BizException(ErrorCodes.VALIDATION_ERROR, "DOCX 解析功能暂未实现");
                    
                default:
                    // 未知类型，尝试按文本解析
                    log.warn("[DocumentService] 未知文件类型: {}, 尝试按文本解析", fileType);
                    return parseTxt(fileBytes);
            }
        } catch (Exception e) {
            log.error("[DocumentService] 文档解析失败: fileType={}", fileType, e);
            throw new BizException(ErrorCodes.SYSTEM_ERROR, "文档解析失败: " + e.getMessage());
        }
    }
    
    @Override
    public List<Document> listDocuments(Long tenantId, Integer pageNum, Integer pageSize) {
        if (tenantId == null) {
            throw new BizException(ErrorCodes.VALIDATION_ERROR, "租户ID不能为空");
        }
        
        // 设置默认值
        if (pageNum == null || pageNum < 1) {
            pageNum = 1;
        }
        if (pageSize == null || pageSize < 1) {
            pageSize = 10;
        }
        if (pageSize > 100) {
            pageSize = 100;  // 限制最大每页数量
        }
        
        // 分页查询
        Page<Document> page = new Page<>(pageNum, pageSize);
        LambdaQueryWrapper<Document> queryWrapper = new LambdaQueryWrapper<>();
        queryWrapper.eq(Document::getTenantId, tenantId)
                    .orderByDesc(Document::getCreateTime);
        
        Page<Document> result = documentMapper.selectPage(page, queryWrapper);
        return result.getRecords();
    }
    
    @Override
    public Document getDocument(Long documentId, Long tenantId) {
        if (documentId == null) {
            throw new BizException(ErrorCodes.VALIDATION_ERROR, "文档ID不能为空");
        }
        if (tenantId == null) {
            throw new BizException(ErrorCodes.VALIDATION_ERROR, "租户ID不能为空");
        }
        
        Document document = documentMapper.selectById(documentId);
        if (document == null) {
            throw new BizException(ErrorCodes.NOT_FOUND, "文档不存在");
        }
        
        // 权限校验：只能查看自己租户的文档
        if (!document.getTenantId().equals(tenantId)) {
            throw new BizException(ErrorCodes.FORBIDDEN, "无权访问该文档");
        }
        
        return document;
    }
    
    @Override
    @Transactional
    public void deleteDocument(Long documentId, Long tenantId) {
        // 1. 权限校验
        Document document = getDocument(documentId, tenantId);
        
        // 2. 删除关联的 Chunk
        chunkService.deleteChunksByDocumentId(documentId);
        
        // 3. 删除文档
        documentMapper.deleteById(documentId);
        
        log.info("[DocumentService] 文档删除成功: documentId={}, tenantId={}", documentId, tenantId);
        
        // TODO: 后续在索引服务中删除 Qdrant 中的向量
    }
    
    @Override
    public void updateDocumentStatus(Long documentId, Integer status) {
        Document document = new Document();
        document.setId(documentId);
        document.setStatus(status);
        if (status == 1) {  // 已索引
            document.setIndexedAt(LocalDateTime.now());
        }
        document.setUpdateTime(LocalDateTime.now());
        documentMapper.updateById(document);
    }
    
    /**
     * 解析 TXT 文件
     */
    private String parseTxt(byte[] fileBytes) {
        // 尝试 UTF-8 编码
        try {
            return new String(fileBytes, StandardCharsets.UTF_8);
        } catch (Exception e) {
            // 如果 UTF-8 失败，尝试 GBK
            try {
                return new String(fileBytes, "GBK");
            } catch (Exception e2) {
                // 如果都失败，使用系统默认编码
                return new String(fileBytes);
            }
        }
    }
    
    /**
     * 解析 Markdown 文件（目前按文本处理，后续可以去除 Markdown 语法）
     */
    private String parseMarkdown(byte[] fileBytes) {
        // 目前按文本处理，后续可以去除 Markdown 语法
        return parseTxt(fileBytes);
    }
    
    /**
     * 根据文件名获取文件类型
     */
    private String getFileType(String filename) {
        if (filename == null || filename.isEmpty()) {
            return "txt";
        }
        
        int lastDotIndex = filename.lastIndexOf('.');
        if (lastDotIndex == -1 || lastDotIndex == filename.length() - 1) {
            return "txt";
        }
        
        return filename.substring(lastDotIndex + 1).toLowerCase();
    }
}
```

**实现要点**：
1. **参数校验**：确保必要参数不为空
2. **文件大小限制**：防止上传过大文件
3. **编码处理**：支持 UTF-8 和 GBK
4. **事务管理**：使用 `@Transactional` 保证数据一致性
5. **错误处理**：使用 `BizException` 统一异常处理
6. **日志记录**：记录关键操作日志

### 步骤6：添加配置项

**文件路径**：`src/main/resources/application.yml`

在现有配置中添加：

```yaml
# RAG 配置
rag:
  # 文档切分配置
  chunk:
    size: 500          # Chunk 大小（字符数）
    overlap: 50        # 重叠大小
    min-size: 50       # 最小 Chunk 大小
  
  # 文档管理配置
  document:
    max-size: 10485760  # 最大文件大小（字节），默认 10MB
```

### 步骤7：添加错误码（可选）

**文件路径**：`src/main/java/com/ityfz/yulu/common/enums/ErrorCodes.java`

在现有错误码中添加：

```java
// 业务 - 知识库
public static final String DOCUMENT_NOT_FOUND = "DOCUMENT_NOT_FOUND";
public static final String DOCUMENT_TOO_LARGE = "DOCUMENT_TOO_LARGE";
public static final String DOCUMENT_PARSE_FAILED = "DOCUMENT_PARSE_FAILED";
```

---

## 七、测试方法

### 7.1 单元测试示例

**文件路径**：`src/test/java/com/ityfz/yulu/knowledge/service/ChunkServiceTest.java`

```java
package com.ityfz.yulu.knowledge.service;

import com.ityfz.yulu.knowledge.entity.Chunk;
import org.junit.jupiter.api.Test;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.boot.test.context.SpringBootTest;

import java.util.List;

import static org.junit.jupiter.api.Assertions.*;

@SpringBootTest
class ChunkServiceTest {
    
    @Autowired
    private ChunkService chunkService;
    
    @Test
    void testChunkText_ShortContent() {
        String content = "这是一个短文本";
        List<Chunk> chunks = chunkService.chunkText(content, 500, 50);
        
        assertEquals(1, chunks.size());
        assertEquals(content, chunks.get(0).getContent());
    }
    
    @Test
    void testChunkText_LongContent() {
        StringBuilder sb = new StringBuilder();
        for (int i = 0; i < 100; i++) {
            sb.append("这是第").append(i).append("段内容。");
        }
        String content = sb.toString();
        
        List<Chunk> chunks = chunkService.chunkText(content, 50, 10);
        
        assertTrue(chunks.size() > 1);
        // 验证每个 Chunk 的长度不超过 chunkSize
        for (Chunk chunk : chunks) {
            assertTrue(chunk.getContentLength() <= 50);
        }
    }
    
    @Test
    void testChunkText_Overlap() {
        String content = "第一段内容。第二段内容。第三段内容。";
        List<Chunk> chunks = chunkService.chunkText(content, 20, 5);
        
        // 验证有重叠
        if (chunks.size() > 1) {
            String firstChunk = chunks.get(0).getContent();
            String secondChunk = chunks.get(1).getContent();
            // 第二个 Chunk 应该包含第一个 Chunk 的结尾部分
            assertTrue(secondChunk.contains(firstChunk.substring(firstChunk.length() - 5)));
        }
    }
}
```

### 7.2 集成测试示例

**文件路径**：`src/test/java/com/ityfz/yulu/knowledge/service/DocumentServiceTest.java`

```java
package com.ityfz.yulu.knowledge.service;

import com.ityfz.yulu.knowledge.entity.Document;
import org.junit.jupiter.api.Test;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.boot.test.context.SpringBootTest;
import org.springframework.transaction.annotation.Transactional;

import java.util.List;

import static org.junit.jupiter.api.Assertions.*;

@SpringBootTest
@Transactional  // 测试后回滚
class DocumentServiceTest {
    
    @Autowired
    private DocumentService documentService;
    
    @Test
    void testUploadDocument_WithText() {
        Long tenantId = 1L;
        String title = "测试文档";
        String content = "这是测试文档的内容。包含多段文字。";
        String source = "测试";
        
        Long documentId = documentService.uploadDocument(tenantId, title, null, content, source);
        
        assertNotNull(documentId);
        
        Document document = documentService.getDocument(documentId, tenantId);
        assertEquals(title, document.getTitle());
        assertEquals(content, document.getContent());
        assertEquals(0, document.getStatus());  // 未索引
    }
    
    @Test
    void testListDocuments() {
        Long tenantId = 1L;
        
        // 先上传几个文档
        documentService.uploadDocument(tenantId, "文档1", null, "内容1", "测试");
        documentService.uploadDocument(tenantId, "文档2", null, "内容2", "测试");
        
        List<Document> documents = documentService.listDocuments(tenantId, 1, 10);
        
        assertTrue(documents.size() >= 2);
    }
    
    @Test
    void testDeleteDocument() {
        Long tenantId = 1L;
        Long documentId = documentService.uploadDocument(tenantId, "待删除文档", null, "内容", "测试");
        
        documentService.deleteDocument(documentId, tenantId);
        
        // 验证文档已删除（应该抛出异常）
        assertThrows(Exception.class, () -> {
            documentService.getDocument(documentId, tenantId);
        });
    }
}
```

### 7.3 手动测试步骤

1. **启动应用**
   ```bash
   mvn spring-boot:run
   ```

2. **使用 Postman 或 curl 测试上传接口**（需要先实现 Controller）
   ```bash
   curl -X POST http://localhost:8080/api/knowledge/document/upload \
     -H "Content-Type: application/json" \
     -H "Authorization: Bearer YOUR_TOKEN" \
     -d '{
       "title": "测试文档",
       "content": "这是测试内容...",
       "source": "用户上传"
     }'
   ```

3. **查看数据库**
   ```sql
   -- 查看文档
   SELECT * FROM knowledge_document;
   
   -- 查看 Chunk
   SELECT * FROM knowledge_chunk WHERE document_id = 1;
   ```

---

## 八、注意事项

### 8.1 编码问题

- **文件编码**：优先使用 UTF-8，如果失败尝试 GBK
- **数据库编码**：确保数据库使用 `utf8mb4` 字符集

### 8.2 性能优化

- **批量插入**：如果文档很大，Chunk 数量多，考虑批量插入
- **异步处理**：文档切分可以异步处理，不阻塞上传接口
- **内容长度限制**：建议限制单个文档的最大长度（如 1MB 文本）

### 8.3 错误处理

- **文件解析失败**：记录错误日志，返回友好错误信息
- **切分失败**：不影响文档保存，但更新状态为"索引失败"
- **数据库异常**：使用事务保证数据一致性

### 8.4 安全性

- **权限校验**：确保用户只能访问自己租户的文档
- **文件大小限制**：防止上传过大文件导致内存溢出
- **文件类型校验**：只允许安全的文件类型

### 8.5 后续扩展

- **PDF 解析**：使用 Apache PDFBox 或 Apache Tika
- **DOCX 解析**：使用 Apache POI
- **图片 OCR**：使用 Tesseract 或云服务 OCR API
- **增量更新**：文档内容变更时，只更新变更的 Chunk

---

## 九、实现检查清单

### 9.1 数据库
- [ ] 创建 `knowledge_document` 表
- [ ] 创建 `knowledge_chunk` 表
- [ ] 验证表结构和索引

### 9.2 实体类
- [ ] 创建 `Document` 实体类
- [ ] 创建 `Chunk` 实体类
- [ ] 验证注解和字段映射

### 9.3 Mapper
- [ ] 创建 `DocumentMapper`
- [ ] 创建 `ChunkMapper`
- [ ] 验证 MyBatis Plus 扫描

### 9.4 Service
- [ ] 实现 `ChunkService` 接口
- [ ] 实现 `DocumentService` 接口
- [ ] 添加配置项
- [ ] 编写单元测试

### 9.5 验证
- [ ] 编译通过
- [ ] 单元测试通过
- [ ] 手动测试上传功能
- [ ] 验证数据库数据

---

## 十、常见问题

### Q1: 切分后的 Chunk 数量太多怎么办？

**A**: 
- 增加 `chunkSize`（如从 500 改为 1000）
- 减少 `overlapSize`（如从 50 改为 20）
- 对于超长文档，考虑先提取摘要再切分

### Q2: 切分时在句子中间截断怎么办？

**A**: 
- `findBestSplitPoint()` 方法会尽量在句子边界切分
- 如果找不到合适的切分点，会在固定位置切分（这是可接受的）

### Q3: 文档内容包含特殊字符导致解析失败？

**A**: 
- 使用 `normalizeContent()` 方法规范化内容
- 处理编码问题（UTF-8、GBK）
- 记录错误日志，便于排查

### Q4: 如何支持更多文件格式？

**A**: 
- 在 `parseDocument()` 方法中添加新的 case
- 引入相应的解析库（如 PDFBox、POI）
- 参考文档中的 TODO 注释

---

**文档完成时间**：2025-01-16  
**适用版本**：YuLu v1.0  
**技术栈**：Spring Boot 2.7.18, MyBatis Plus 3.5.5, MySQL 8.0

































